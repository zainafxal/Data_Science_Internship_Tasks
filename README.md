# ğŸ“Š Data Science Internship Tasks

---

## ğŸ“ Task 1: EDA on Spotify Tracks Dataset

- **Dataset used:** Spotify Tracks Dataset from Kaggle  
- **Steps done:**
  - Loaded data
  - Cleaned data (handled missing values, removed duplicates)
  - Visualizations (bar charts, histograms, correlation heatmap)
- **Tools used:** Pandas, Matplotlib, Seaborn  
- **Summary of findings:**
  - 114,000 rows and 21 columns in the dataset
  - Identified missing values in specific columns
  - Noted various audio features and their distributions  
- **How to run:** Open the Jupyter notebook inside `Task 1 - EDA on Spotify Tracks Dataset/`

---

## ğŸ“ Task 2: Sentiment Analysis

- **Dataset used:** IMDB Reviews  
- **Steps:**
  - Preprocessing (cleaning text data)
  - TF-IDF vectorization
  - Model training and evaluation  
- **Classifier used:** Logistic Regression  
- **Accuracy / F1-score:** 85%  
- **How to run:** Jupyter notebook in `Task 2 - Sentiment Analysis/`

---

## ğŸ“ Task 3: Image Classification

- **Dataset used:** CIFAR-10  
- **Steps:**
  - Data augmentation
  - Model training (Convolutional Neural Networks)
  - Evaluation of model performance  
- **Tools used:** TensorFlow, Keras  
- **Accuracy:** 90%  
- **How to run:** Jupyter notebook in `Task 3 - Image Classification/`

---

## ğŸ“ Task 4: Time Series Forecasting

- **Dataset used:** Stock Prices  
- **Steps:**
  - Data preprocessing
  - Feature engineering
  - Model training (ARIMA, LSTM)  
- **Tools used:** Pandas, Statsmodels, TensorFlow  
- **How to run:** Jupyter notebook in `Task 4 - Time Series Forecasting/`

---

## ğŸ”§ How to Run the Code

Install requirements:
```bash
pip install -r requirements.txt
```
---

## ğŸ“¸ Visuals

* Screenshots are stored inside the /Visuals/ folder

* Includes: correlation heatmap (Task 1), model evaluation (Task 2), etc.


